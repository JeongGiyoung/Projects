{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cd67ac",
   "metadata": {},
   "source": [
    "# # necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1425623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab('C:/mecab/mecab-ko-dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfddb9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-44e82c571a84>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "<ipython-input-6-44e82c571a84>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n"
     ]
    }
   ],
   "source": [
    "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])\n",
    "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
    "\n",
    "# reviews 열에서 중복인 내용이 있다면 중복 제거\n",
    "total_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
    "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data['reviews'].replace('', np.nan, inplace=True)\n",
    "test_data.drop_duplicates(subset = ['reviews'], inplace=True)\n",
    "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "\n",
    "test_data['reviews'].replace('', np.nan, inplace=True)\n",
    "test_data = test_data.dropna(how='any')\n",
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n",
    "\n",
    "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
    "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
    "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "\n",
    "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
    "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)\n",
    "negative_word_count = Counter(negative_words)\n",
    "positive_word_count = Counter(positive_words)\n",
    "\n",
    "X_train = train_data['tokenized'].values\n",
    "y_train = train_data['label'].values\n",
    "X_test= test_data['tokenized'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
    "max_len = 80\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "path = \"C:/Sources/Projects/빅데이터과정_파이널project_유튜브 화장품 정보/res/300data_straightener/result/sensitivityAnalysis/sensitivityAnalysis_best_model_forNavershopping_Review.h5\"\n",
    "loaded_model = load_model(path)\n",
    "\n",
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = mecab.morphs(new_sentence)\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
    "\n",
    "  score = float(loaded_model.predict(pad_new, verbose = 0))\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))\n",
    "\n",
    "tmp = pd.read_csv('C:/Sources/Projects/빅데이터과정_파이널project_유튜브 화장품 정보/res/300data_straightener/result/sensitivityAnalysis/crawledData_naverReviews_VodanaStraightner_blue40.csv')\n",
    "\n",
    "def sentiment_predict_NaverShoppingReviews(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = mecab.morphs(new_sentence)\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
    "\n",
    "  score = float(loaded_model.predict(pad_new, verbose = 0))\n",
    "\n",
    "  if(score > 0.5):\n",
    "    positive_reviews.append(score)\n",
    "  else:\n",
    "    negative_reviews.append(score)\n",
    "  \n",
    "  return positive_reviews, negative_reviews\n",
    "\n",
    "reviews = tmp['review']\n",
    "\n",
    "positive_reviews = list()\n",
    "negative_reviews = list()\n",
    "\n",
    "def rate_n_or_p_reviews(reviews) :\n",
    "  for review in reviews :\n",
    "    positive_reviews, negative_reviews = sentiment_predict_NaverShoppingReviews(review)\n",
    "  total = len(positive_reviews)+len(negative_reviews)\n",
    "  return (f\"positive : {len(positive_reviews) / total * 100} % , negative : {len(negative_reviews) / total * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038739f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result = rate_n_or_p_reviews(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d56692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive : 81.0 % , negative : 19.0 % '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a673c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
